---
title: "Glossary Table"
permalink: /glossary/
layout: splash
---

<table>
  <thead>
    <tr>
      <th scope="col">Term</th>
      <th scope="col">Definition</th>
      <th scope="col">Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">Foundation Model</th>
        <td>
            Foundation models, sometimes known as base models, are powerful artificial intelligence (AI) models that are 
            trained on a massive amount of data and can be adapted to a wide range of tasks. They serve as the base or 
            building blocks for crafting more specialized applications. These more specialized applications are the
            main task for the AI Engineering teams.
        </td>
        <td>
            The term "foundation model" was coined by the Stanford Institute for Human-Centered Artificial Intelligence 
            (HAI) in 2021.
        </td>
    </tr>
    <tr>
      <th scope="row">LLM</th>
        <td>
            Large Language Model (LLM) is the technical term and conceptually the beginning of the named Foundation Models.
            A Large Language Model (LLM) is a specific, advanced type of machine learning model used within the broader 
            field of Natural Language Processing (NLP). NLP is the overall field that enables computers to understand 
            and process human language, while an LLM is huge trained model for achieving many NLP tasks, such as generating 
            text, translation, and summarization, by using deep learning on massive datasets. 
        </td>
        <td>
            NLP based on Transformers is the foundation of LLMs.
        </td>
    </tr>
    <tr>
      <th scope="row">LMM</th>
        <td>
            Large Multimodal Models (aka, MLLMs - Multimodal LLMs) expand the capabilities of traditional large language 
            models (LLMs), which are primarily focused on processing and generating text. By integrating multiple types 
            of data, LMMs enable more complex and versatile applications that require the synthesis and interpretation 
            of both textual and nontextual information, such as text, images, video, audio, and more.
        </td>
        <td>
            This term is related to the concept of Multimodal AI which refers to machine learning models capable of 
            processing and integrating information from multiple modalities or types of data. These modalities can 
            include text, images, audio, video and other forms of sensory input.
        </td>
    </tr>
    <tr>
      <th scope="row">LxM</th>
        <td>
            Large "x" Models family. An LxM is just an umbrella term for representing the LLM, LMM and further terminologies.
            It's another way of naming the Foundation Models (FM).
        </td>
        <td>
           TODO 
        </td>
    </tr>
    <tr>
      <th scope="row">SLM</th>
        <td>
            Small language models (SLMs) in this context are AI models that are trained on smaller, more focused 
            amounts of data compared to large language models. Despite their smaller size, SLMs can perform a variety 
            of tasks, such as text generation, summarization, translation, and classification. While they may not match 
            the extensive capabilities of LLMs, SLMs are often more resource efficient and can be highly effective for specific, targeted applications. 
        </td>
        <td>
           TODO 
        </td>
    </tr>
    <tr>
      <th scope="row">AI Engineering</th>
        <td>
            Refers to the process of building applications on top of foundation models. Many terms are being used to 
            describe the process of building applications on top of foundation models, including ML engineering, 
            MLOps, AIOps, LLMOps, etc.
        </td>
        <td>
           TODO 
        </td>
    </tr>
    <tr>
      <th scope="row">Prompt Engineering</th>
        <td>
            It is the art of asking a Generative AI model questions in natural language so that the model responds 
            according to our needs.
        </td>
        <td>
           TODO 
        </td>
    </tr>
    <tr>
      <th scope="row">Prompt Context</th>
        <td>
            Prompt context is background information or details provided in a prompt that help guide an AI's response 
            to be more relevant and specific.
        </td>
        <td>
           TODO 
        </td>
    </tr>
    <tr>
      <th scope="row">Context Window</th>
        <td>
            The "context window" in GenAI refers to the amount of information a model can process and "remember" at one 
            time, like a short-term memory. It is measured in tokens, which are pieces of words, images, or video. 
            A larger context window allows the AI to handle longer conversations and larger documents by retaining more 
            of the input and output without forgetting the beginning
        </td>
        <td>
           TODO 
        </td>
    </tr>
    <tr>
      <th scope="row">GenAI Token</th>
        <td>
            A token is the smallest unit into which text data (or not text) can be broken down for an AI model to process.
            Whether a transformer AI model is processing text, images, audio clips, videos or another modality, it will 
            translate the data into tokens. This process is known as tokenization. Large language models have varying 
            token limits, which dictate the amount of text they can process at once, combining both the input prompt 
            and the output completion. The token limit determines the model's "context window" the amount of information 
            it can consider at any one time. So the number of supported tokens of a model is frequently used as a 
            measure of the model power.
        </td>
        <td>
           TODO 
        </td>
    </tr>
    <tr>
        <th scope="row">TODO</th>
        <td>
            TODO
        </td>
        <td>
               TODO 
        </td>
    </tr>
  </tbody>
</table>