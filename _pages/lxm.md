---
title: "LxM Ecosystem Table"
permalink: /lxm/
layout: splash
---

<table>
  <thead>
    <tr>
      <th scope="col">Ecosystem</th>
      <th scope="col">Model</th>
      <th scope="col">Release Date</th>
      <th scope="col">Status</th>
      <th scope="col">Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">OpenAI</th>
        <td>
            GPT-1
        </td>
        <td>
            11 June 2018
        </td>
        <td>
            Active
        </td>
        <td>
            Trained with BookCorpus 4.5 GB of text, from 7,000 unpublished books of various genres.
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            GPT-2
        </td>
        <td>
            14 February  2019
        </td>
        <td>
            Active
        </td>
        <td>
            Trained with WebText: 40 GB of text, 8 million documents, from 45 million webpages upvoted on Reddit.
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            GPT-3
        </td>
        <td>
            28 May, 2020
        </td>
        <td>
            Active
        </td>
        <td>
            Trained with 499 billion tokens consisting of CommonCrawl (570 GB), WebText, English Wikipedia, and two books corpora 
            (Books1 and Books2)
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            GPT-3.5
        </td>
        <td>
            15 March 2022
        </td>
        <td>
            Active
        </td>
        <td>
            Undisclosed
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            GPT-4
        </td>
        <td>
            14 March 2023
        </td>
        <td>
            Active
        </td>
        <td>
            Undisclosed
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            GPT-4o
        </td>
        <td>
            13 May 2024
        </td>
        <td>
            Active
        </td>
        <td>
            Undisclosed
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            GPT-4.5
        </td>
        <td>
            27 February 2025
        </td>
        <td>
            Active
        </td>
        <td>
            Undisclosed
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
           GPT-4.1 
        </td>
        <td>
            14 April 2025
        </td>
        <td>
            Active
        </td>
        <td>
            Undisclosed
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
           GPT-5
        </td>
        <td>
           7 August 2025
        </td>
        <td>
            Active
        </td>
        <td>
            Undisclosed
        </td>
    </tr>
    <tr>
      <th scope="row">Google</th>
        <td>
            LaMDA
        </td>
        <td>
           11 May 2022
        </td>
        <td>
           Active
        </td>
        <td>
           Currently, LaMDA is not available to the public but is accessible to select developers for testing and refinement.
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
             Bard
        </td>
        <td>
           21 March 2023
        </td>
        <td>
           Discontinued
        </td>
        <td>
           Google's first experimental chatbot service based on LaMDA
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
             Gemini 1.0 Nano
        </td>
        <td>
           6 December 2023
        </td>
        <td>
           Discontinued
        </td>
        <td>
           Designed for on-device tasks and first available in Google's Pixel 8 Pro
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
             Gemini 1.0 Pro
        </td>
        <td>
           13 December 2023
        </td>
        <td>
           Discontinued
        </td>
        <td>
           Designed for a diverse range of tasks
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
             Gemini 1.0 Ultra
        </td>
        <td>
           	8 February 2024
        </td>
        <td>
           Discontinued
        </td>
        <td>
           Google's most powerful offering in the Gemini 1.0 family
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Gemini 1.5 Pro
        </td>
        <td>
           	15 February 2024
        </td>
        <td>
           Discontinued
        </td>
        <td>
           As a successor to the 1.0 series of models, 1.5 Pro offers significantly increased context size 
           (up to 1 million tokens). It is designed to be the most capable model in the Gemini 1.5 family.
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Gemini 1.5 Flash
        </td>
        <td>
           	14 May 2024
        </td>
        <td>
           Discontinued
        </td>
        <td>
            TODO
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Gemini 2.0 Flash
        </td>
        <td>
           30 January 2025	
        </td>
        <td>
           Active
        </td>
        <td>
           	Developed by Google with a focus on multimodality, agentic capabilities, and speed
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Gemini 2.0 Flash-Lite
        </td>
        <td>
           1 February 2025
        </td>
        <td>
           Active
        </td>
        <td>
           	First-ever Gemini Flash-Lite model designed for cost-efficiency and speed	
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Gemini 2.5 Pro
        </td>
        <td>
           25 March 2025
        </td>
        <td>
           Active
        </td>
        <td>
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Gemini 2.5 Flash
        </td>
        <td>
          17 April 2025 
        </td>
        <td>
           Active
        </td>
        <td>
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Gemini 2.5 Flash-Lite
        </td>
        <td>
          17 June 2025
        </td>
        <td>
           Active
        </td>
        <td>
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Gemini 2.5 Flash Image (Nano Banana)
        </td>
        <td>
          26 August 2025
        </td>
        <td>
           Active
        </td>
        <td>
        </td>
    </tr>
    <tr>
      <th scope="row">Meta</th>
        <td>
            OPT 
        </td>
        <td>
            May 2022
        </td>
        <td>
            Non-commercial
        </td>
        <td>
            GPT-3 architecture with some adaptations from Megatron. Uniquely, the training logbook written by the team was published.
            Corpus size 180 billion tokens.
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Galactica
        </td>
        <td>
            November 2022
        </td>
        <td>
            TODO
        </td>
        <td>
            Corpus size 106 billion tokens
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Llama
        </td>
        <td>
            24 February 2023
        </td>
        <td>
            Discontinued
        </td>
        <td>
            Corpus size 1.4 trillion tokens
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Chameleon
        </td>
        <td>
            June 2024
        </td>
        <td>
            TODO
        </td>
        <td>
            Corpus size 4.4 trillion tokens
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Llama 2
        </td>
        <td>
            18 July 2023
        </td>
        <td>
            Discontinued
        </td>
        <td>
            Corpus size 2 trillion tokens
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Code Llama
        </td>
        <td>
            24 August 2023
        </td>
        <td>
            Discontinued
        </td>
        <td>
            TODO
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Llama 3
        </td>
        <td>
            April 18, 2024
        </td>
        <td>
            Active
        </td>
        <td>
            Corpus size 15 trillion tokens
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Llama 3.1
        </td>
        <td>
            23 July 2024
        </td>
        <td>
            Active
        </td>
        <td>
            Corpus size 15.6 trillion tokens
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Llama 3.2
        </td>
        <td>
            September 25, 2024	
        </td>
        <td>
            Active
        </td>
        <td>
            Corpus size 9 trillion tokens
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Llama 3.3
        </td>
        <td>
            December 7, 2024
        </td>
        <td>
            Active
        </td>
        <td>
            Corpus size 15 trillion tokens
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Llama 4
        </td>
        <td>
            April 5, 2025
        </td>
        <td>
            Active
        </td>
        <td>
            Corpus size 40 trillion tokens
        </td>
    </tr>
    <tr>
      <th scope="row">Microsoft</th>
        <td>
            Copilot
        </td>
        <td>
            September 21, 2023
        </td>
        <td>
           Active
        </td>
        <td>
            Based on Microsoft's Prometheus model, which is based on OpenAI's GPT-4 series
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Phi-1
        </td>
        <td>
        </td>
        <td>
        </td>
        <td>
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Phi-1.5
        </td>
        <td>
        </td>
        <td>
        </td>
        <td>
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Phi-2
        </td>
        <td>
           December 2023 
        </td>
        <td>
        </td>
        <td>
            1.4T tokens
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Phi-3
        </td>
        <td>
            April 2024
        </td>
        <td>
        </td>
        <td>
            Phi-3-mini, Phi-3-small, Phi-3-medium and Phi-3-vision
        </td>
    </tr>
    <tr>
      <th scope="row"></th>
        <td>
            Phi-4
        </td>
        <td>
        </td>
        <td>
        </td>
        <td>
            Phi-4-mini and Phi-4-multimodal
        </td>
    </tr>
    <tr>
      <th scope="row">Antropic</th>
        <td>
        </td>
        <td>
        </td>
        <td>
        </td>
        <td>
        </td>
    </tr>
 </tbody>
</table>

